{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fSnPULfyLEI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ8VrJ8rK715"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import itertools\n",
        "import copy\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import tree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path, class_column, label_column, extra_columns=[]):\n",
        "    df = pd.read_csv(file_path)\n",
        "    Y = df[class_column]\n",
        "    Y_true = df[label_column]\n",
        "    X = df.drop([class_column, label_column], axis=1)\n",
        "    if len(extra_columns) > 0:\n",
        "        X.drop(extra_columns, axis=1, inplace=True)\n",
        "    #cols = X.columns\n",
        "    #X[cols] = X[cols].astype(str)\n",
        "    return X, Y, Y_true"
      ],
      "metadata": {
        "id": "doMajdhQLFSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KL_divergence(p, q): \n",
        "    eps = 1e-15\n",
        "    sum = 0\n",
        "    for i in range(len(p)):  # iterating over each data example\n",
        "        pi = p[i]\n",
        "        qi = q[i]\n",
        "        for j in range(len(pi)):  # iterating over each class probability \n",
        "            pij = pi[j] + eps\n",
        "            qij = qi[j] + eps\n",
        "            sum += (pij * math.log(pij / qij))\n",
        "            \n",
        "    return sum"
      ],
      "metadata": {
        "id": "Tenib2EJLFPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_base_predictions(X, class_rates):\n",
        "    classes = list(class_rates.keys())\n",
        "    rates = list(class_rates.values())\n",
        "\n",
        "    base_labels = []\n",
        "    for i,row in X.iterrows(): \n",
        "        b = random.choices(classes, rates)[0]\n",
        "        base_y = [class_rates[k] for k in classes]  # [1 if k==b else 0 for k in classes]\n",
        "        base_labels.append(base_y)\n",
        "        \n",
        "    return base_labels"
      ],
      "metadata": {
        "id": "nXKNBvD2LFMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tree_leaves(model):\n",
        "    n_nodes = model.tree_.node_count\n",
        "    children_left = model.tree_.children_left\n",
        "    children_right = model.tree_.children_right\n",
        "\n",
        "    n_leaves = 0\n",
        "    max_depth = 0\n",
        "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
        "    while len(stack) > 0:\n",
        "        node_id, depth = stack.pop()\n",
        "        if depth > max_depth: \n",
        "            max_depth = depth\n",
        "\n",
        "        is_split_node = children_left[node_id] != children_right[node_id]   # Different left and right children means split node\n",
        "        if is_split_node:\n",
        "            stack.append((children_left[node_id], depth + 1))\n",
        "            stack.append((children_right[node_id], depth + 1))\n",
        "        else:\n",
        "            n_leaves += 1\n",
        "            \n",
        "    return n_nodes, n_leaves, max_depth"
      ],
      "metadata": {
        "id": "SrYLyDLALFJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rule_feature_value(thresh, is_left):\n",
        "    if not binning_features:\n",
        "        return 0 if is_left else 1\n",
        "\n",
        "    if is_left: \n",
        "        if thresh <= 0.5:\n",
        "            return 0\n",
        "        else:\n",
        "            return 0.5   # means either 0 or 1\n",
        "    else:\n",
        "        if thresh > 1.0:\n",
        "            return 2\n",
        "        else:\n",
        "            return 1.5   # means either 1 or 2"
      ],
      "metadata": {
        "id": "gwBhBzaP8fMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pattern_description (pattern):\n",
        "\n",
        "    antecedents = []\n",
        "    for attr in list(pattern.keys()): \n",
        "        if (attr not in meta_cols) and (pattern[attr] != -1):\n",
        "            antecedents.append(attr + '=' + str(pattern[attr]))\n",
        "    \n",
        "    pred = pattern['pred']\n",
        "    sup = pattern['support']\n",
        "    conf = pattern['confidence']\n",
        "    acc = pattern['accuracy']\n",
        "    desc = 'If {}, then {} (sup: {}, conf: {}, acc: {})'.format(' & '.join(antecedents), class_titles[pred], sup, conf, acc)\n",
        "    return desc"
      ],
      "metadata": {
        "id": "cvAeZAQuplO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_save_rules(model, feature_names, leaves_stats, n_rows, output_path):\n",
        "    rows_list = []\n",
        "    node_features = model.tree_.feature\n",
        "    node_thresholds = model.tree_.threshold\n",
        "    children_left = model.tree_.children_left\n",
        "    children_right = model.tree_.children_right\n",
        "\n",
        "    stack = [(0, [])]  # start with the root node id (0) and the empty path\n",
        "    while len(stack) > 0:\n",
        "        node_id, path = stack.pop()\n",
        "\n",
        "        is_split_node = children_left[node_id] != children_right[node_id]   # Different left and right children means split node\n",
        "        if is_split_node:\n",
        "            left_path = copy.deepcopy(path)\n",
        "            right_path = copy.deepcopy(path)\n",
        "            thresh = node_thresholds[node_id]\n",
        "            left_value = get_rule_feature_value(thresh, True)\n",
        "            right_value = get_rule_feature_value(thresh, False)\n",
        "            left_path.append((node_id, left_value))\n",
        "            right_path.append((node_id, right_value))\n",
        "            stack.append((children_left[node_id], left_path))\n",
        "            stack.append((children_right[node_id], right_path))\n",
        "        else:\n",
        "            stat = leaves_stats[node_id]\n",
        "            row = {}\n",
        "            row = {c:-1 for c in feature_names}\n",
        "            row['pred'] = stat['class']\n",
        "            row['support'] = stat['support'] / n_rows\n",
        "            row['confidence'] = stat['confidence']\n",
        "            row['accuracy'] = stat['accuracy']\n",
        "            for node_item in path:\n",
        "                node, value = node_item\n",
        "                feature_index = node_features[node]\n",
        "                feature_name = feature_names[feature_index]\n",
        "                row[feature_name] = value\n",
        "                \n",
        "            print(get_pattern_description(row))\n",
        "            rows_list.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows_list)\n",
        "    df.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "1D1TO6m7Al0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictions(Y_list, classes, base_labels, preds, pred_leaves, leaves_stats):\n",
        "    true_count = 0\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    conf_labels = []\n",
        "    for i,y in enumerate(Y_list):\n",
        "        p = preds[i]\n",
        "        p_leaf = pred_leaves[i]\n",
        "        item = leaves_stats[p_leaf]\n",
        "        class_covers = item['class_covers']\n",
        "        \n",
        "        if p == y:\n",
        "            true_count += 1\n",
        "            \n",
        "        conf_y = [class_covers[k] if k in class_covers else 0 for k in classes]\n",
        "        conf_labels.append(conf_y)\n",
        "        \n",
        "        pred_y = [1 if k==p else 0 for k in classes]\n",
        "        pred_labels.append(pred_y)\n",
        "        \n",
        "        true_y = [1 if k==y else 0 for k in classes]\n",
        "        true_labels.append(true_y)\n",
        "        \n",
        "    print('True, prediction, and base labels:', list(zip(true_labels, pred_labels, conf_labels, base_labels, pred_leaves))[:5])\n",
        "        \n",
        "    base_KL = KL_divergence(true_labels, base_labels)\n",
        "    final_KL = KL_divergence(true_labels, conf_labels)\n",
        "    info_gain = base_KL - final_KL\n",
        "    tree_acc = true_count / len(Y_list)\n",
        "    return base_KL, final_KL, info_gain, tree_acc"
      ],
      "metadata": {
        "id": "3RpEItWcLFGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_tree(X, Y, Y_true, classes, base_labels, model_params, feature_names, class_names):\n",
        "    print(\"----------------------\")\n",
        "    print('Training and evaluating tree with params:', model_params)\n",
        "    t1 = datetime.datetime.now()\n",
        "    Y_list = Y.to_list()\n",
        "    Y_true_list = Y_true.to_list()\n",
        "    \n",
        "    model = tree.DecisionTreeClassifier(**model_params)\n",
        "    model.fit(X, Y)\n",
        "    \n",
        "    preds = model.predict(X)\n",
        "    pred_leaves = model.apply(X)\n",
        "    \n",
        "    leaves_stats = {}\n",
        "    for i,n in enumerate(pred_leaves):\n",
        "        y = Y_list[i]\n",
        "        y_true = Y_true_list[i]\n",
        "        p = preds[i]\n",
        "        c = 1 if y == p else 0\n",
        "        a = 1 if ((c == 1) and (y == y_true)) else 0\n",
        "        if n in leaves_stats: \n",
        "            item = leaves_stats[n]\n",
        "            item['support'] += 1\n",
        "            item['confidence'] += c\n",
        "            item['accuracy'] += a\n",
        "            if item['class'] != p: \n",
        "                print('Different prediction {} with class {} found for leaf {}!'.format(p, item['class'], n))\n",
        "            \n",
        "            class_covers = item['class_covers']\n",
        "            if y in class_covers:\n",
        "                class_covers[y] = class_covers[y] + 1\n",
        "            else:\n",
        "                class_covers[y] = 1\n",
        "        else: \n",
        "            class_covers = {}\n",
        "            class_covers[y] = 1\n",
        "            leaves_stats[n] = { 'class': p, 'support': 1, 'confidence': c, 'accuracy': a, 'class_covers': class_covers }\n",
        "            \n",
        "    for n,item in leaves_stats.items():\n",
        "        sup = item['support']  # sum(covers.values())\n",
        "        conf = item['confidence']\n",
        "        acc = item['accuracy']\n",
        "        item['confidence'] = conf / sup\n",
        "        item['accuracy'] = acc / conf\n",
        "        class_covers = item['class_covers']\n",
        "        leaves_stats[n]['class_covers'] = {k:(v/sup) for k,v in class_covers.items()}\n",
        "    print('Leaves stats:', leaves_stats)\n",
        "    \n",
        "    n_nodes, n_leaves, max_depth = count_tree_leaves(model)\n",
        "    print('Tree has {} nodes, {} leaves, and max depth of {}'.format(n_nodes, n_leaves, max_depth))\n",
        "    \n",
        "    base_KL, final_KL, info_gain, tree_acc = evaluate_predictions(Y_list, classes, base_labels, preds, pred_leaves, leaves_stats)\n",
        "    \n",
        "    t2 = datetime.datetime.now()\n",
        "    print('Base KL:', base_KL)\n",
        "    print('Final KL:', final_KL)\n",
        "    print('Info gain:', info_gain)\n",
        "    print('Accuracy:', tree_acc)\n",
        "    print('Time for training and evaluating the tree:', t2-t1)\n",
        "    \n",
        "    tree_txt = tree.export_text(model, feature_names=feature_names, show_weights=True)\n",
        "    print(tree_txt)\n",
        "    \n",
        "    #fig = plt.figure(figsize=(25,20))\n",
        "    #tree.plot_tree(model, feature_names=feature_names, class_names=class_names, filled=True)\n",
        "    #plt.show()\n",
        "    #fig.savefig(\"tree.png\")\n",
        "    \n",
        "    #tree.export_graphviz(model, \"tree\", feature_names=feature_names, class_names=class_names)\n",
        "    \n",
        "    return model, leaves_stats, n_leaves, info_gain, tree_acc"
      ],
      "metadata": {
        "id": "GSV50r2wLFDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_class_titles (ds_name):\n",
        "\tctitles = {}\n",
        "\tname_parts = ds_name.split('_')\n",
        "\tif len(name_parts) <= 1:\n",
        "\t\treturn ctitles\n",
        "\t\n",
        "\tn_classes = len(name_parts[1:])\n",
        "\tfor i,p in enumerate(name_parts[1:]):\n",
        "\t\tctitles[i] = p\n",
        "\t\tif binning_classes:\n",
        "\t\t\tctitles[i + n_classes] = 'maybe ' + p\n",
        "\t\t\n",
        "\treturn ctitles"
      ],
      "metadata": {
        "id": "K4JbQ1N8VcN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main process: \n",
        "\n",
        "current_setting_path = '/content/drive/My Drive/Python Projects/POEM Pipeline Results/current_setting.txt'\n",
        "with open(current_setting_path, 'r') as f:\n",
        "    current_setting_title = f.read().splitlines()[0]\n",
        "    print('Current setting:', current_setting_title)\n",
        "\n",
        "title_parts = current_setting_title.split('_')\n",
        "model_name = title_parts[0]\n",
        "dataset_name = '_'.join(title_parts[1:]) \n",
        "\n",
        "old_process = False\n",
        "binning_classes = False\n",
        "binning_features = False\n",
        "\n",
        "meta_cols = ['pred', 'support', 'confidence', 'accuracy']\n",
        "class_titles = extract_class_titles(dataset_name)\n",
        "class_names = [v for k,v in class_titles.items()]\n",
        "\n",
        "drive_result_path = '/content/drive/My Drive/Python Projects/POEM Pipeline Results/' + model_name + '_' + dataset_name\n",
        "if old_process:\n",
        "    drive_result_path += '_old'\n",
        "concepts_file = 'image_concepts.csv'\n",
        "concepts_path = drive_result_path + \"/\" + concepts_file\n",
        "!cp \"$concepts_path\" '.'\n",
        "\n",
        "t_start = datetime.datetime.now()\n",
        "X, Y, Y_true = load_data(concepts_file, 'pred', 'label', ['id', 'file', 'path'])   # Y is CNN model predictions, while Y_true is ground truth labels\n",
        "\n",
        "feature_names = list(X.columns)\n",
        "n_rows = len(Y.index)\n",
        "class_counts = Y.value_counts().to_dict()\n",
        "class_rates = {k:(v/n_rows) for k,v in class_counts.items()}\n",
        "classes = list(class_rates.keys())\n",
        "num_classes = len(classes)\n",
        "print('class_rates:', class_rates)\n",
        "\n",
        "base_labels = compute_base_predictions(X, class_rates)\n",
        "\n",
        "params_grid = {\n",
        "    'criterion': ['entropy'], \n",
        "    'min_samples_leaf': [0.01, 0.03, 0.05, 0.1, 0.15, 0.2]\n",
        "    #'max_leaf_nodes': list(range(2, 10, 2)),\n",
        "    #'max_depth': list(range(1, 5, 1))\n",
        "}\n",
        "\n",
        "param_keys = list(params_grid.keys())\n",
        "param_values = list(params_grid.values())\n",
        "param_combinations = list(itertools.product(*param_values))\n",
        "#output_path = 'cart_patterns.csv'\n",
        "output_path_list = []\n",
        "results = []\n",
        "print('Parameter combinations:', param_combinations)\n",
        "\n",
        "for comb in param_combinations:\n",
        "    params = {k:v for k,v in zip(param_keys, comb)}\n",
        "    model, leaves_stats, n_leaves, info_gain, tree_acc = train_evaluate_tree(X, Y, Y_true, classes, base_labels, params, feature_names, class_names)\n",
        "    results.append({'params': params, 'leaves': n_leaves, 'info_gain': info_gain})\n",
        "    output_path = 'cart_patterns_' + str(params['min_samples_leaf']) + '.csv'\n",
        "    extract_save_rules(model, feature_names, leaves_stats, n_rows, output_path)\n",
        "    output_path_list.append(output_path)\n",
        "    \n",
        "t_end = datetime.datetime.now()\n",
        "print(\"----------------------\")\n",
        "print('Total time:', t_end - t_start)\n",
        "print('Results:', results)\n",
        "\n",
        "#!cp $output_path \"$drive_result_path\"\n",
        "for path in output_path_list:\n",
        "    !cp $path \"$drive_result_path\""
      ],
      "metadata": {
        "id": "cTkRw-KgLE-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}