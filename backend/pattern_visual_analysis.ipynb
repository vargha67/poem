{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jpi2EzzQmcnI"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from IPython.display import display, display_png\n",
        "\n",
        "pd.options.display.max_columns = None"
      ],
      "metadata": {
        "id": "0QNzGMve_0Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data (image_concepts_path, ids_patterns_path, cart_patterns_path, exp_patterns_path):\n",
        "\n",
        "    image_concepts = pd.read_csv(image_concepts_path)\n",
        "    ids_patterns = pd.read_csv(ids_patterns_path)\n",
        "    cart_patterns = pd.read_csv(cart_patterns_path)\n",
        "    exp_patterns = pd.read_csv(exp_patterns_path)\n",
        "\n",
        "    return image_concepts, ids_patterns, cart_patterns, exp_patterns"
      ],
      "metadata": {
        "id": "n36JkmFYtV-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_patterns ():\n",
        "\n",
        "    all_patterns_list = []\n",
        "\t\n",
        "    if \"exp\" in rule_methods: \n",
        "        exp_patterns = pd.read_csv(exp_patterns_path)\n",
        "        exp_patterns['method'] = 'Exp'\n",
        "        all_patterns_list.append(exp_patterns)\n",
        "        \n",
        "    if \"ids\" in rule_methods:\n",
        "        ids_patterns = pd.read_csv(ids_patterns_path)\n",
        "        ids_patterns['method'] = 'IDS'\n",
        "        all_patterns_list.append(ids_patterns)\n",
        "        \n",
        "    if \"cart\" in rule_methods:\n",
        "        cart_patterns = pd.read_csv(cart_patterns_path)\n",
        "        cart_patterns['method'] = 'CART'\n",
        "        all_patterns_list.append(cart_patterns)\n",
        "\n",
        "    all_patterns = pd.concat(all_patterns_list, ignore_index=True)\n",
        "\n",
        "    # ids_patterns['method'] = 'IDS'\n",
        "    # cart_patterns['method'] = 'CART'\n",
        "    # exp_patterns['method'] = 'Exp'\n",
        "    # all_patterns = pd.concat([ids_patterns, cart_patterns, exp_patterns], ignore_index=True)\n",
        "\n",
        "    patterns_to_remove = []\n",
        "    exp_patterns_count = 0\n",
        "    \n",
        "    for i,pattern in all_patterns.iterrows():\n",
        "        if remove_inactivated_patterns:\n",
        "            # Removing patterns with \"no\" features, because they're not very accurate and useful: \n",
        "            to_remove = False\n",
        "            for attr in list(pattern.index): \n",
        "                pattern_value = pattern[attr]\n",
        "                if (attr not in meta_cols) and (pattern_value == low_value):\n",
        "                    to_remove = True\n",
        "                    break\n",
        "                    \n",
        "            if to_remove:\n",
        "                print('Pattern {{{}}} to be removed because of having inactivated features!'.format(get_pattern_description(pattern)))\n",
        "                patterns_to_remove.append(i)\n",
        "                continue\n",
        "\n",
        "        if pattern['method'] != 'Exp':\n",
        "            continue\n",
        "\n",
        "        # Using only the specified maximum number of Exp patterns: \n",
        "        # exp_patterns_count += 1\n",
        "        # if exp_patterns_count > exp_num_patterns:\n",
        "        #     print('Exp pattern {{{}}} to be removed because of max number of Exp patterns ({})!'.format(get_pattern_description(pattern), exp_num_patterns))\n",
        "        #     patterns_to_remove.append(i)\n",
        "        #     continue\n",
        "\n",
        "        # Handling those patterns by Exp Tables which have confidence lower than 0.5 and need to be inverted to be meaningful and useful: \n",
        "        # pred = pattern['pred']\n",
        "        # conf = pattern['confidence']\n",
        "        # if conf < 0.5:\n",
        "        #     new_pred = pred\n",
        "        #     new_conf = conf\n",
        "        #     classes = list(class_titles.keys())\n",
        "        #     if len(classes) == 2:\n",
        "        #         new_pred = 1 if pred == 0 else 0\n",
        "        #         new_conf = 1.0 - conf\n",
        "        #     else:\n",
        "        #         # Need to find the new prediction and accurate confidence value, as there may be more than one other classes in this case: \n",
        "        #         pattern_cp = pattern.copy(deep=True)\n",
        "        #         for c in classes:\n",
        "        #             if pred == c:\n",
        "        #                 continue\n",
        "        #             pattern_cp['pred'] = c\n",
        "        #             supporting_indices = find_images_supporting_pattern(image_concepts, pattern_cp)\n",
        "        #             matching_indices = find_images_matching_pattern(image_concepts, pattern_cp, supporting_indices)\n",
        "        #             temp_conf = len(matching_indices) / len(supporting_indices)\n",
        "        #             if temp_conf > new_conf:\n",
        "        #                 new_pred = c\n",
        "        #                 new_conf = temp_conf\n",
        "\n",
        "        #     all_patterns.loc[i, 'pred'] = new_pred\n",
        "        #     all_patterns.loc[i, 'confidence'] = new_conf\n",
        "        #     print('Exp pattern with pred {} and conf {} changed to new pred {} and new conf {}'.format(pred, conf, new_pred, new_conf))\n",
        "\n",
        "    if len(patterns_to_remove) > 0:\n",
        "        all_patterns.drop(patterns_to_remove, axis=0, inplace=True)\n",
        "\n",
        "    all_patterns['support'] = all_patterns['support'].round(2)\n",
        "    all_patterns['confidence'] = all_patterns['confidence'].round(2)\n",
        "    all_patterns['accuracy'] = all_patterns['accuracy'].round(2)\n",
        "\n",
        "    concept_cols = list(set(all_patterns.columns) - set(meta_cols))\n",
        "    all_patterns['score'] = all_patterns.apply(lambda p: compute_pattern_score(p, concept_cols), axis=1)\n",
        "\n",
        "    group_cols = list(all_patterns.columns)\n",
        "    group_cols.remove('method')\n",
        "    all_patterns_grouped = all_patterns.groupby(group_cols, as_index=False)\n",
        "\n",
        "    all_patterns = all_patterns_grouped.agg({'method': lambda p: ', '.join(p.unique())})\n",
        "\n",
        "    all_patterns.sort_values(by=['score', 'confidence', 'support', 'accuracy', 'method'], ascending=False, inplace=True)\n",
        "    all_patterns.reset_index(drop=True, inplace=True)\n",
        "    all_patterns.insert(loc=0, column='index', value=(all_patterns.index + 1))\n",
        "    all_patterns['score'] = all_patterns['score'].round(2)\n",
        "\n",
        "    all_patterns = all_patterns.iloc[:max_patterns]\n",
        "    all_patterns = all_patterns.loc[:, (all_patterns != -1).any(axis=0)]\n",
        "    #all_patterns.dropna(axis=1, how='all', inplace=True)\n",
        "    concept_cols = list(set(all_patterns.columns) - set(meta_cols))\n",
        "\n",
        "    image_concepts = pd.read_csv(concepts_path)\n",
        "    concepts_to_keep = set(concept_cols).union(set(['pred', 'label', 'id', 'file', 'path']))\n",
        "    concepts_to_remove = list(set(image_concepts.columns) - concepts_to_keep)\n",
        "    image_concepts.drop(concepts_to_remove, axis=1, inplace=True)\n",
        "\n",
        "    return all_patterns, image_concepts, concept_cols"
      ],
      "metadata": {
        "id": "1fkDcoMzCa4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_images_supporting_pattern (image_concepts, pattern):\n",
        "\n",
        "    df = image_concepts.copy()\n",
        "    for attr in list(pattern.index): \n",
        "        pattern_value = pattern[attr]\n",
        "        if (attr not in meta_cols) and (pattern_value != -1):\n",
        "            if (not binning_features) or (pattern_value % 1 == 0): \n",
        "                df = df[df[attr] == pattern_value]\n",
        "            else:\n",
        "                # Handling the case of 0.5 or 1.5 values for a pattern feature: \n",
        "                a = math.floor(pattern_value)\n",
        "                b = math.ceil(pattern_value)\n",
        "                print('attr {} with value {}, floor {}, and ceil {}'.format(attr, pattern_value, a, b))\n",
        "                df = df[(df[attr] == a) | (df[attr] == b)]\n",
        "\n",
        "    supporting_indices = list(df.index.values)\n",
        "    return supporting_indices"
      ],
      "metadata": {
        "id": "wJsMfBUAod1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_images_matching_pattern (image_concepts, pattern, supporting_indices=None): \n",
        "\n",
        "    if supporting_indices is None:\n",
        "        supporting_indices = find_images_supporting_pattern(image_concepts, pattern)\n",
        "    pattern_label = pattern['pred']\n",
        "\n",
        "    matching_indices = []\n",
        "    supporting_labels = list(image_concepts.iloc[supporting_indices]['pred'])\n",
        "\n",
        "    for i,label in enumerate(supporting_labels):\n",
        "        if label == pattern_label:\n",
        "            matching_indices.append(supporting_indices[i])\n",
        "\n",
        "    return matching_indices"
      ],
      "metadata": {
        "id": "oEzI72e2tMcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_images_supporting_pattern_not_matching (image_concepts, pattern, supporting_indices=None, matching_indices=None):\n",
        "\n",
        "    if supporting_indices is None:\n",
        "        supporting_indices = find_images_supporting_pattern(image_concepts, pattern)\n",
        "    if matching_indices is None:\n",
        "        matching_indices = find_images_matching_pattern(image_concepts, pattern, supporting_indices)\n",
        "    \n",
        "    nonmatching_indices = sorted(list(set(supporting_indices) - set(matching_indices)))\n",
        "    return nonmatching_indices"
      ],
      "metadata": {
        "id": "v4gMhaMwEun-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_images_matching_pattern_wrong_predicted (image_concepts, pattern, matching_indices=None):\n",
        "\n",
        "    if matching_indices is None:\n",
        "        matching_indices = find_images_matching_pattern(image_concepts, pattern)\n",
        "\n",
        "    wrong_indices = []\n",
        "    matching_concepts = image_concepts.iloc[matching_indices][['pred', 'label']]\n",
        "\n",
        "    for i,row in matching_concepts.iterrows():\n",
        "        if row['pred'] != row['label']:\n",
        "            wrong_indices.append(i)\n",
        "\n",
        "    return wrong_indices"
      ],
      "metadata": {
        "id": "mpsXQvqqEg7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_images_having_concept (image_concepts, target_concept): \n",
        "\n",
        "    image_target_concepts = list(image_concepts[target_concept])\n",
        "    matching_indices = []\n",
        "\n",
        "    for i,val in enumerate(image_target_concepts):\n",
        "        if val == 1:\n",
        "            matching_indices.append(i)\n",
        "\n",
        "    return matching_indices"
      ],
      "metadata": {
        "id": "A8OUC1xe3y9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pattern_description (pattern):\n",
        "\n",
        "    antecedents = []\n",
        "    for attr in list(pattern.index): \n",
        "        if (attr not in meta_cols) and (pattern[attr] != -1):\n",
        "            antecedents.append(attr + '=' + str(pattern[attr]))\n",
        "    \n",
        "    pred = pattern['pred']\n",
        "    sup = pattern['support']\n",
        "    conf = pattern['confidence']\n",
        "    acc = pattern['accuracy']\n",
        "    desc = 'If {}, then {} (sup: {}, conf: {}, acc: {})'.format(' & '.join(antecedents), class_titles[pred], sup, conf, acc)\n",
        "    return desc"
      ],
      "metadata": {
        "id": "-_pJBRWITd51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_description (img_concepts, target_concept=None, target_channel=None):\n",
        "\n",
        "    desc = 'Predicted ' + r'$\\it{' + class_titles[img_concepts['pred']] + '}$'\n",
        "    desc += ', Labeled ' + r'$\\it{' + class_titles[img_concepts['label']] + '}$'\n",
        "\n",
        "    if target_concept is None: \n",
        "        high_concepts = []\n",
        "        mid_concepts = []\n",
        "        for attr in list(img_concepts.index):\n",
        "            if (attr not in ['pred', 'label', 'id', 'file', 'path']):\n",
        "                if binning_features:\n",
        "                    if img_concepts[attr] == mid_value:\n",
        "                        mid_concepts.append(attr)\n",
        "                    elif img_concepts[attr] == high_value: \n",
        "                        high_concepts.append(attr)\n",
        "                else:\n",
        "                    if img_concepts[attr] == high_value:\n",
        "                        high_concepts.append(attr)\n",
        "    \n",
        "        if len(high_concepts) > 0:\n",
        "            part_title = '\\nHigh concepts: ' if binning_features else '\\nConcepts: '\n",
        "            desc += part_title + r'$\\it{' + ', '.join(high_concepts) + '}$'\n",
        "        if len(mid_concepts) > 0:\n",
        "            desc += '\\nMid concepts: ' + r'$\\it{' + ', '.join(mid_concepts) + '}$'\n",
        "        if (len(high_concepts) == 0) and (len(mid_concepts) == 0):\n",
        "            desc += '\\nNo concepts activated'\n",
        "    else:\n",
        "        desc += '\\nConcept ' + r'$\\it{' + target_concept + '}$ highlighted'\n",
        "        if target_channel != None:\n",
        "            desc += ' (filter ' + r'$\\it{' + str(target_channel) + '}$)'\n",
        "\n",
        "    return desc"
      ],
      "metadata": {
        "id": "Gla1PkwGApaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_image_activation_images (image_fname, activations_path, target_concept=None):\n",
        "\n",
        "    ind = image_fname.rfind('.')\n",
        "    image_fname_raw = image_fname[:ind]\n",
        "\n",
        "    activations_info = {}\n",
        "    for fname in os.listdir(activations_path):\n",
        "        if not fname.startswith(image_fname_raw + \"_\"): \n",
        "            continue\n",
        "\n",
        "        ind = fname.rfind('.')\n",
        "        ext = fname[ind:]\n",
        "        if (target_concept != None) and (not fname.endswith(target_concept + ext)):\n",
        "            continue\n",
        "\n",
        "        ind = len(image_fname_raw + \"_\")\n",
        "        ind2 = fname.rfind(ext)\n",
        "        main_body = fname[ind:ind2]\n",
        "        parts = main_body.split('_')\n",
        "\n",
        "        feature_value_cat = None\n",
        "        channel = None\n",
        "        concept = None\n",
        "        if len(parts) == 2:\n",
        "            channel = int(parts[0])\n",
        "            concept = parts[1]\n",
        "        elif len(parts) == 3:   # the case of binned features where the mid or high value of concept is also part of the file name\n",
        "            feature_value_cat = parts[0]\n",
        "            channel = int(parts[1])\n",
        "            concept = parts[2]\n",
        "        else:\n",
        "            print('Error: Name of image file {} does not include feature value, concept and channel parts: {}'.format(fname, parts))\n",
        "            continue\n",
        "\n",
        "        if (target_concept != None) and (concept != target_concept):\n",
        "            print('Error: Concept {} in name of file {} not matching the target concept {}'.format(concept, fname, target_concept))\n",
        "            continue\n",
        "\n",
        "        full_path = os.path.join(activations_path, fname)\n",
        "        if concept in activations_info: \n",
        "            activations_info[concept].append((channel, full_path))\n",
        "        else:\n",
        "            activations_info[concept] = [(channel, full_path)]\n",
        "\n",
        "    return activations_info"
      ],
      "metadata": {
        "id": "UxMQI13UCZwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image_items_for_display (matching_image_concepts, activations_path=None, target_concept=None):\n",
        "\n",
        "    image_items = []\n",
        "    for i, (ind, img_concepts) in enumerate(matching_image_concepts.iterrows()):\n",
        "        img_item = {}\n",
        "        img_path = img_concepts['path']\n",
        "        img_fname = img_concepts['file']\n",
        "\n",
        "        if target_concept is None:\n",
        "            img_item['path'] = img_path\n",
        "            img_item['desc'] = get_image_description(img_concepts)\n",
        "            image_items.append(img_item)\n",
        "        else:\n",
        "            activations_info = list_image_activation_images(img_fname, activations_path, target_concept)\n",
        "            \n",
        "            if target_concept in activations_info:\n",
        "                inf = activations_info[target_concept]\n",
        "                item = inf[0]\n",
        "                img_item['path'] = item[1]\n",
        "                img_item['desc'] = get_image_description(img_concepts, target_concept, target_channel=item[0])\n",
        "                image_items.append(img_item)\n",
        "            else:\n",
        "                print('Error: Activations info for image {} does not include the target concept {}: {}'.format(img_fname, target_concept, activations_info))\n",
        "\n",
        "    return image_items"
      ],
      "metadata": {
        "id": "xUPTTuK_Xcr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images (image_items, n_cols=3): \n",
        "\n",
        "    n_images = len(image_items)\n",
        "    if n_images == 0:\n",
        "        return\n",
        "\n",
        "    n_rows = math.ceil(n_images / n_cols)\n",
        "\n",
        "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4))\n",
        "    axs = axs.flatten()\n",
        "    for i, img_item in enumerate(image_items):\n",
        "        ax = axs[i]\n",
        "        ax.axes.xaxis.set_visible(False)\n",
        "        ax.axes.yaxis.set_visible(False)\n",
        "        img_path = img_item['path']\n",
        "        img_desc = img_item['desc']\n",
        "        img = cv2.imread(img_path)\n",
        "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        title = ax.set_title(img_desc, fontsize=11)\n",
        "        #title.set_y(1.05)\n",
        "        #fig.subplots_adjust(top=0.8, bottom=0.8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "drnYATsAo8CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_matching_pattern (pattern, image_concepts, activations_path=None, target_concept=None, max_images=20):\n",
        "\n",
        "    matching_indices = find_images_matching_pattern(image_concepts, pattern)\n",
        "    matching_image_concepts = image_concepts.iloc[matching_indices].iloc[:max_images]\n",
        "    image_items = prepare_image_items_for_display(matching_image_concepts, activations_path, target_concept)\n",
        "    \n",
        "    print('\\nImages matching pattern {{{}}}'.format(get_pattern_description(pattern)) + \n",
        "          (', with concept {} highlighted\\n'.format(target_concept) if target_concept != None else '\\n'))\n",
        "    plot_images(image_items, n_cols=4)"
      ],
      "metadata": {
        "id": "NgHyK4LDcs4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_supporting_pattern_not_matching (pattern, image_concepts, activations_path=None, target_concept=None, max_images=20):\n",
        "\n",
        "    nonmatching_indices = find_images_supporting_pattern_not_matching(image_concepts, pattern)\n",
        "    nonmatching_image_concepts = image_concepts.iloc[nonmatching_indices].iloc[:max_images]\n",
        "    image_items = prepare_image_items_for_display(nonmatching_image_concepts, activations_path, target_concept)\n",
        "\n",
        "    print('\\nImages supporting but not matching pattern {{{}}}'.format(get_pattern_description(pattern)) + \n",
        "          (', with concept {} highlighted\\n'.format(target_concept) if target_concept != None else '\\n'))\n",
        "    plot_images(image_items, n_cols=4)"
      ],
      "metadata": {
        "id": "SSBQMyNSdt4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_matching_pattern_wrong_predicted (pattern, image_concepts, activations_path=None, target_concept=None, max_images=20):\n",
        "\n",
        "    wrong_indices = find_images_matching_pattern_wrong_predicted(image_concepts, pattern)\n",
        "    wrong_image_concepts = image_concepts.iloc[wrong_indices].iloc[:max_images]\n",
        "    image_items = prepare_image_items_for_display(wrong_image_concepts, activations_path, target_concept)\n",
        "\n",
        "    print('\\nImages matching but predicted wrong for pattern {{{}}}'.format(get_pattern_description(pattern)) + \n",
        "          (', with concept {} highlighted\\n'.format(target_concept) if target_concept != None else '\\n'))\n",
        "    plot_images(image_items, n_cols=4)"
      ],
      "metadata": {
        "id": "jeRSgESUd-mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_activated_concepts (img_concepts, activations_path):\n",
        "\n",
        "    img_id = img_concepts['id']\n",
        "    img_fname = img_concepts['file']\n",
        "    activations_info = list_image_activation_images(img_fname, activations_path)\n",
        "    \n",
        "    for con,inf in activations_info.items():\n",
        "        image_items = []\n",
        "        for item in inf:\n",
        "            img_item = {}\n",
        "            img_item['path'] = item[1]\n",
        "            img_item['desc'] = get_image_description(img_concepts, target_concept=con, target_channel=item[0])\n",
        "            image_items.append(img_item)\n",
        "\n",
        "        print('\\nImage {} with file name {}, with concept {} highlighted\\n'.format(img_id, img_fname, con))\n",
        "        plot_images(image_items, n_cols=3)"
      ],
      "metadata": {
        "id": "zE9a-uKheIvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_having_concept (image_concepts, target_concept, activations_path=None, max_images=20):\n",
        "\n",
        "    matching_indices = find_images_having_concept(image_concepts, target_concept)\n",
        "    matching_image_concepts = image_concepts.iloc[matching_indices].iloc[:max_images]\n",
        "    image_items = prepare_image_items_for_display(matching_image_concepts, activations_path, target_concept)\n",
        "    \n",
        "    print('\\nImages having concept {}\\n'.format(target_concept))\n",
        "    plot_images(image_items, n_cols=4)"
      ],
      "metadata": {
        "id": "etec2SFp3KVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_single_images (image_concepts, target_concept=None, target_channel=None):\n",
        "\n",
        "    image_items = []\n",
        "    for i, (ind, img_concepts) in enumerate(image_concepts.iterrows()):\n",
        "        img_item = {}\n",
        "        img_item['path'] = img_concepts['path']\n",
        "        img_item['desc'] = get_image_description(img_concepts, target_concept, target_channel)\n",
        "        image_items.append(img_item)\n",
        "\n",
        "    plot_images(image_items, n_cols=4)"
      ],
      "metadata": {
        "id": "AfTNz7NyjCC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_class_titles (ds_name):\n",
        "    ctitles = {}\n",
        "    name_parts = ds_name.split('_')\n",
        "    if len(name_parts) <= 1:\n",
        "        return ctitles\n",
        "\n",
        "    n_classes = len(name_parts[1:])\n",
        "    for i,p in enumerate(name_parts[1:]):\n",
        "        ctitles[i] = p\n",
        "        if binning_classes:\n",
        "            ctitles[i + n_classes] = 'maybe ' + p\n",
        "\n",
        "    return ctitles"
      ],
      "metadata": {
        "id": "4KaQmBfHVDBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pattern_score (row, concept_cols):\n",
        "\n",
        "    sup = row['support']\n",
        "    conf = row['confidence']\n",
        "    size = 0\n",
        "\n",
        "    for col in concept_cols:\n",
        "        if row[col] != -1:\n",
        "            size += 1\n",
        "\n",
        "    score = (sup * (conf ** 2)) / (size ** 2)   # (sup * conf) / size   # (sup * (conf ** 2)) / (size ** 2)  # (sup * (conf ** 2)) / (math.sqrt(size))\n",
        "    return score"
      ],
      "metadata": {
        "id": "mjQKqsIVuEE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_value_desc (val):\n",
        "    \n",
        "    if val == -1:\n",
        "        return ''\n",
        "\n",
        "    if not binning_features:\n",
        "        return 'yes' if (val == high_value) else 'no'\n",
        "\n",
        "    if val == high_value:\n",
        "        return 'yes'\n",
        "    elif val == mid_value:\n",
        "        return 'maybe'\n",
        "    elif val == low_value:\n",
        "        return 'no'\n",
        "    else:\n",
        "        a = math.floor(val)\n",
        "        b = math.ceil(val)\n",
        "        if (a == low_value) and (b == mid_value):\n",
        "            return 'no/maybe'\n",
        "        elif (a == mid_value) and (b == high_value):\n",
        "            return 'maybe/yes'\n",
        "    \n",
        "    return ''"
      ],
      "metadata": {
        "id": "dJ-b3fcU7I4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_setting_path = '/content/drive/My Drive/Python Projects/POEM Pipeline Results/current_setting.txt'\n",
        "with open(current_setting_path, 'r') as f:\n",
        "    current_setting_title = f.read().splitlines()[0]\n",
        "    print('Current setting:', current_setting_title)\n",
        "\n",
        "title_parts = current_setting_title.split('_')\n",
        "model_name = title_parts[0]\n",
        "dataset_name = '_'.join(title_parts[1:]) \n",
        "\n",
        "old_process = True\n",
        "binning_classes = False\n",
        "binning_features = False\n",
        "class_titles = extract_class_titles(dataset_name)\n",
        "\n",
        "high_value = 2 if binning_features else 1\n",
        "mid_value = 1\n",
        "low_value = 0\n",
        "\n",
        "remove_inactivated_patterns = False\n",
        "rule_methods = ['cart']\n",
        "if not old_process:\n",
        "    rule_methods.append('exp')\n",
        "    rule_methods.append('ids')\n",
        "\n",
        "ids_param = 0.01\n",
        "cart_param = 0.03\n",
        "exp_param = 0.03\n",
        "max_patterns = 10\n",
        "\n",
        "drive_result_path = '/content/drive/My Drive/Python Projects/POEM Pipeline Results/' + model_name + '_' + dataset_name\n",
        "if old_process:\n",
        "    drive_result_path += '_old'\n",
        "\n",
        "dataset_file = 'dataset.zip'\n",
        "drive_dataset_dir = drive_result_path + '/' + dataset_file\n",
        "!cp \"$drive_dataset_dir\" '.'\n",
        "!unzip -qq -n $dataset_file -d '.'\n",
        "\n",
        "concepts_file = 'image_concepts.csv'\n",
        "ids_patterns_file = 'ids_patterns' + ('_' + str(ids_param) if (ids_param != None) else '') + '.csv'\n",
        "cart_patterns_file = 'cart_patterns' + ('_' + str(cart_param) if (cart_param != None) else '') + '.csv'\n",
        "exp_patterns_file = 'exp_patterns' + ('_' + str(exp_param) if (exp_param != None) else '') + '.csv'\n",
        "activation_images_file = 'activation_images.zip'\n",
        "\n",
        "concepts_path = drive_result_path + '/' + concepts_file\n",
        "ids_patterns_path = drive_result_path + '/' + ids_patterns_file\n",
        "cart_patterns_path = drive_result_path + '/' + cart_patterns_file\n",
        "exp_patterns_path = drive_result_path + '/' + exp_patterns_file\n",
        "activation_images_path = drive_result_path + '/' + activation_images_file\n",
        "\n",
        "!cp \"$concepts_path\" '.'\n",
        "!cp \"$ids_patterns_path\" '.'\n",
        "!cp \"$cart_patterns_path\" '.'\n",
        "!cp \"$exp_patterns_path\" '.'\n",
        "!cp \"$activation_images_path\" '.'\n",
        "\n",
        "!unzip -qq -n $activation_images_file -d '.'\n",
        "activations_path = 'activation_images'"
      ],
      "metadata": {
        "id": "DIL0U6okLRoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_cols = ['index', 'pred', 'support', 'confidence', 'accuracy', 'method', 'score']\n",
        "#image_concepts, ids_patterns, cart_patterns, exp_patterns = load_data(concepts_path, ids_patterns_path, cart_patterns_path, exp_patterns_path)\n",
        "all_patterns, image_concepts, concept_cols = load_patterns()\n",
        "\n",
        "# Use a copy of the patterns dataframe for display:\n",
        "all_patterns_df = all_patterns.copy(deep=True)\n",
        "all_patterns_df.set_index('index', inplace=True)\n",
        "all_patterns_df['pred'] = all_patterns_df['pred'].apply(lambda p: class_titles[p])\n",
        "\n",
        "# For test:\n",
        "all_patterns_df['support'] = all_patterns_df['support'].apply(lambda p: p if p >= 0.03 else 0.03)\n",
        "\n",
        "renamed_cols = {}\n",
        "for con in concept_cols:\n",
        "    all_patterns_df[con] = all_patterns_df[con].apply(lambda v: get_feature_value_desc(v))\n",
        "    if '-' in con:\n",
        "        i = con.rfind('-')\n",
        "        renamed_cols[con] = con[:i]\n",
        "\n",
        "#renamed_cols = {}\n",
        "for col in meta_cols:\n",
        "    renamed_cols[col] = col.upper()\n",
        "    if col is 'pred':\n",
        "        renamed_cols[col] = 'PREDICTION'\n",
        "\n",
        "all_patterns_df.rename(columns=renamed_cols, inplace=True)\n",
        "all_patterns_df = all_patterns_df.rename_axis(None)\n",
        "\n",
        "display(all_patterns_df)"
      ],
      "metadata": {
        "id": "pUr1xRTSDud7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pattern_index = 5\n",
        "#pattern = all_patterns.iloc[3]\n",
        "pattern = all_patterns.loc[all_patterns['index'] == pattern_index].iloc[0]\n",
        "\n",
        "display_images_matching_pattern(pattern, image_concepts)\n"
      ],
      "metadata": {
        "id": "Lqgjj8WTGgwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display_images_matching_pattern(pattern, image_concepts, activations_path, target_concept='blue-c')\n"
      ],
      "metadata": {
        "id": "rPQ9WICoFq7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display_images_supporting_pattern_not_matching(pattern, image_concepts)\n"
      ],
      "metadata": {
        "id": "lwiBjB3cQNsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display_images_supporting_pattern_not_matching(pattern, image_concepts, activations_path, target_concept='red')\n"
      ],
      "metadata": {
        "id": "HTi_VOl-SUD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display_images_matching_pattern_wrong_predicted(pattern, image_concepts)\n"
      ],
      "metadata": {
        "id": "UcvNn-32QOGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display_images_matching_pattern_wrong_predicted(pattern, image_concepts, activations_path, target_concept='shelf')\n"
      ],
      "metadata": {
        "id": "nFQR2iuiSdGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_concepts = image_concepts[image_concepts['id'] == 25].iloc[0]\n",
        "\n",
        "display_image_activated_concepts(img_concepts, activations_path)\n"
      ],
      "metadata": {
        "id": "85AdbfsNIgJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "full_image_concepts = pd.read_csv(concepts_path)\n",
        "target_concept = 'red-c'\n",
        "display_images_having_concept(full_image_concepts, target_concept, activations_path)\n"
      ],
      "metadata": {
        "id": "mxBdd_ilFUXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test visualizations: \n",
        "\n",
        "image_concepts_list = [\n",
        "    {'sea': 1, 'pred': 0, 'label': 0, 'file': '00003622.png', 'path': '00003622.png'},\n",
        "    {'sea': 1, 'pred': 1, 'label': 1, 'file': '00000404.png', 'path': '00000404.png'},\n",
        "    {'sea': 1, 'pred': 0, 'label': 1, 'file': '00000886.png', 'path': '00000886.png'},\n",
        "    {'sea': 1, 'pred': 1, 'label': 1, 'file': '00001312.png', 'path': '00001312.png'},\n",
        "    {'sea': 1, 'pred': 1, 'label': 1, 'file': '00001933.png', 'path': '00001933.png'},\n",
        "    {'sea': 1, 'pred': 1, 'label': 1, 'file': '00002914.png', 'path': '00002914.png'},\n",
        "    {'sea': 1, 'pred': 1, 'label': 1, 'file': '00003013.png', 'path': '00003013.png'},\n",
        "    {'sea': 1, 'pred': 1, 'label': 1, 'file': '00004180.png', 'path': '00004180.png'},\n",
        "]\n",
        "\n",
        "image_concepts = pd.DataFrame(image_concepts_list)\n",
        "target_concept = 'sea'\n",
        "target_channel = 144\n",
        "\n",
        "display_single_images(image_concepts, target_concept, target_channel)\n"
      ],
      "metadata": {
        "id": "G6WeJfH6pdaF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}